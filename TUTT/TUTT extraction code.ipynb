{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "........................................................................\n",
      ">>> working on  Nyamutumbu09April24.sql\n",
      ">>> Trimming database\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "__enter__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6897/1632447148.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mtrimmed_database\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrim_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;31m# # Restoring Database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 192\u001b[0;31m         \u001b[0mextraction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_database\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrimmed_database\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprocessing_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m         \u001b[0;31m# ----- get facility id,version and last time stamp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6897/1632447148.py\u001b[0m in \u001b[0;36mrestore_database\u001b[0;34m(self, backup_file, time_)\u001b[0m\n\u001b[1;32m     59\u001b[0m         \u001b[0mconnection\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_connection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0;31m# Drop existing EHR schemas before restoring new database\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcursor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcursor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m             \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SET foreign_key_checks = 0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mcursor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'SELECT SCHEMA_NAME FROM information_schema.schemata;'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: __enter__"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import time\n",
    "import datetime\n",
    "from csv import reader\n",
    "from dateutil import parser\n",
    "import glob\n",
    "from pathlib import Path\n",
    "from dateutil.parser import parse\n",
    "import warnings\n",
    "import pandas_dedupe\n",
    "import sqlite3\n",
    "import sys \n",
    "from datetime import datetime\n",
    "import json\n",
    "import subprocess\n",
    "import mysql.connector\n",
    "import configparser\n",
    "import numpy as np\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "class Extraction:\n",
    "\n",
    "    def __init__(self, folder_path ) -> None:\n",
    "        self.folder_path = folder_path\n",
    "\n",
    "    def get_faility_db_list(self):\n",
    "        facility_db_list = [f for f in os.listdir(self.folder_path) if f.endswith('.sql') and not f.startswith(\"modified\")]\n",
    "        return facility_db_list\n",
    "    \n",
    "    \n",
    "    # Get database connection\n",
    "    def get_connection(self):\n",
    "         user, password, host, port  = self.get_db_params()\n",
    "         connection = mysql.connector.connect(user=user, password=password, host=host, port=port)\n",
    "         return connection\n",
    "    \n",
    "\n",
    "    def get_db_params(self):\n",
    "        config = configparser.ConfigParser()\n",
    "        config.read('config.ini') \n",
    "        user = config.get('Database', 'user')\n",
    "        password = config.get('Database', 'password')\n",
    "        host = config.get('Database', 'host')\n",
    "        port = config.get('Database', 'port')\n",
    "        return user, password, host, port  \n",
    "    \n",
    "    \n",
    "    def restore_database(self, backup_file, time_):\n",
    "        backup_file = backup_file.replace(\"\\\\\", \"/\")\n",
    "        # Helper function for deleting existing schemas\n",
    "        def drop_database(cursor, schema):\n",
    "            schemas_to_drop = ['client', 'consultation', 'deduplication', 'facility', 'mrs', 'provider', 'report', 'terminology', 'zimepms']\n",
    "            if schema in schemas_to_drop:\n",
    "                cursor.execute(f'DROP DATABASE {schema}')\n",
    "                print(f\"    >>> DROPPED [{schema}]\")\n",
    "        # Establish connection to the server\n",
    "        connection = self.get_connection()\n",
    "        # Drop existing EHR schemas before restoring new database\n",
    "        with connection.cursor() as cursor:\n",
    "            cursor.execute('SET foreign_key_checks = 0')\n",
    "            cursor.execute('SELECT SCHEMA_NAME FROM information_schema.schemata;')\n",
    "            schemas = [row[0] for row in cursor.fetchall()]\n",
    "            for schema in schemas:\n",
    "                drop_database(cursor, schema)\n",
    "        # Get DB credentials \n",
    "        user, password , host, port = self.get_db_params()\n",
    "        restore_command = f\"mysql -u {user} -p{password} -h {host} -P {port} < {backup_file}\"\n",
    "        try:\n",
    "            print(\" >>> Restoring database: \"+restore_command)\n",
    "            subprocess.run(restore_command, shell=True, check=True)\n",
    "            print(' >>> DATABASE RESTORE [SUCCESSFUL>>>]')\n",
    "        except Exception as e:\n",
    "            log_file = os.path.join(os.getcwd(), 'logs.txt')\n",
    "            with open(log_file, 'a') as f:\n",
    "                f.write(f'{time_} {backup_file} {str(e)}\\n')\n",
    "    \n",
    "\n",
    "    # remove database mrs from sql file \n",
    "    def trim_database(self, database_path_and_filename):\n",
    "        with open(database_path_and_filename, \"r\", encoding='ISO-8859-1') as f:\n",
    "            content = f.read()\n",
    "\n",
    "        start_text = \"USE `mrs`;\"\n",
    "        updated_text = content.split(start_text)[0]\n",
    "\n",
    "        directory, filename = os.path.split(database_path_and_filename)\n",
    "        new_filename = f\"modified_{filename}\"\n",
    "        file_path = os.path.join(directory, new_filename)\n",
    "\n",
    "        with open(file_path, \"w\",encoding='utf-8') as f:\n",
    "            f.write(updated_text)\n",
    "\n",
    "        return file_path\n",
    "    \n",
    "\n",
    "    def get_facility_details(self,mapping_file,latest_site_id):\n",
    "        facility_name = mapping_file.loc[mapping_file['Facility ID'] == latest_site_id] [\"Facility\"].values\n",
    "        if facility_name.size > 0:\n",
    "            facility_name = facility_name[0]\n",
    "            district_name = mapping_file.loc[mapping_file['Facility ID'] == latest_site_id] [\"District\"].values\n",
    "            if district_name.size > 0:\n",
    "                district_name = district_name[0]\n",
    "            else:\n",
    "                district_name = \"\"\n",
    "            province_name = mapping_file.loc[mapping_file['Facility ID'] == latest_site_id] [\"Province\"].values\n",
    "            if province_name.size > 0:\n",
    "                province_name = province_name[0]\n",
    "            else:\n",
    "                province_name = \"\"\n",
    "        else:\n",
    "            facility_name = \"\"\n",
    "            district_name = \"\"\n",
    "            province_name = \"\"\n",
    "        return facility_name,district_name,province_name\n",
    "    \n",
    "\n",
    "    def get_reason_for_not_eiligible1(self,row):\n",
    "            if row[\"Eligible for TPT at enrolment\"] == \"No\":\n",
    "                if row[\"sign_and_symptoms_of_active_tb\"] == \"Yes\":\n",
    "                        return \"Sign and symptoms of active tb\"\n",
    "                elif row[\"patient_currently_on_tb_treatment\"] ==\"Yes\":\n",
    "                        return \"Patient currently on tb treatment\"\n",
    "                elif row[\"completed_ipt_in_the_last_three_years\"] == \"Yes\":\n",
    "                        return \"Completed ipt in the last three years\"\n",
    "                elif row[\"signs_of_active_liver_disease\"] == \"Yes\":\n",
    "                        return \"Signs of active liver disease\"\n",
    "                elif row[\"heavy_alcohol_use\"] == \"Yes\":\n",
    "                        return \"Heavy alcohol use\"\n",
    "                elif row[\"severe_peripheral_neuropathy\"] == \"Yes\":\n",
    "                        return \"Severe peripheral neuropathy\"\n",
    "            else:\n",
    "                return \"\"\n",
    "\n",
    "    def get_reason_for_not_eiligible(self,row):\n",
    "            if row[\"Eligible for TPT\"] == \"No\":\n",
    "                if row[\"sign_and_symptoms_of_active_tb\"] == \"Yes\":\n",
    "                        return \"Sign and symptoms of active tb\"\n",
    "                elif row[\"patient_currently_on_tb_treatment\"] ==\"Yes\":\n",
    "                        return \"Patient currently on tb treatment\"\n",
    "                elif row[\"completed_ipt_in_the_last_three_years\"] == \"Yes\":\n",
    "                        return \"Completed ipt in the last three years\"\n",
    "                elif row[\"signs_of_active_liver_disease\"] == \"Yes\":\n",
    "                        return \"Signs of active liver disease\"\n",
    "                elif row[\"heavy_alcohol_use\"] == \"Yes\":\n",
    "                        return \"Heavy alcohol use\"\n",
    "                elif row[\"severe_peripheral_neuropathy\"] == \"Yes\":\n",
    "                        return \"Severe peripheral neuropathy\"\n",
    "            else:\n",
    "                return \"\"\n",
    "            \n",
    "    # def get_first_tpt_completion_date(self,row):\n",
    "    #         if row[\"TPT Start Regimen\"].startswith(\"3\"):\n",
    "    #             return row[\"TPT start date\"] + 50\n",
    "    #         else:\n",
    "    #             return \"\"\n",
    "   \n",
    "\n",
    "    def get_mapping_file(self):\n",
    "        mapping_file = pd.read_csv(\"mapping_file.csv\")\n",
    "        mapping_file['Facility ID'] = mapping_file['Facility ID'].str.strip()\n",
    "        return mapping_file\n",
    "    \n",
    "    \n",
    "    def extracting_data(self,sql,connection):\n",
    "        try:\n",
    "            connection = self.get_connection()\n",
    "            df = pd.read_sql(sql,connection)\n",
    "            connection.close()\n",
    "            return df\n",
    "        except Exception as e:  # noqa: E722\n",
    "            print(e)\n",
    "            return None\n",
    "    \n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    processing_time = datetime.now().strftime(\"%d/%m/%Y %H:%M:%S\")\n",
    "    extraction  = Extraction(\"./\")\n",
    "    mapping_file = extraction.get_mapping_file()\n",
    "    facilities = extraction.get_faility_db_list()\n",
    "    folder_path = extraction.folder_path\n",
    "    connection = extraction.get_connection()\n",
    "  \n",
    "    for filename in facilities:\n",
    "        print()\n",
    "        print(\"........................................................................\")\n",
    "        print(\">>> working on \", filename)\n",
    "        print(\">>> Trimming database\")\n",
    "        trimmed_database = extraction.trim_database(filename)\n",
    "        # # Restoring Database\n",
    "        extraction.restore_database(trimmed_database, processing_time)\n",
    "\n",
    "        # ----- get facility id,version and last time stamp\n",
    "        df_facility = extraction.extracting_data(\"\"\"\n",
    "                                SELECT facility_id, time FROM consultation.patient\n",
    "                                where time <= now()\n",
    "                                order by time desc\n",
    "                                limit 1               \n",
    "                            \"\"\", connection)\n",
    "        if df_facility.empty:\n",
    "             print(\">>> database is empty\")\n",
    "             continue\n",
    "        \n",
    "        latest_site_id, latest_timestamp = df_facility.values.tolist()[0]\n",
    "        version= \"\"\n",
    "        first_time_stamp = \"\"\n",
    "\n",
    "        facility_name , district_name, province_name =  extraction.get_facility_details(mapping_file,latest_site_id)\n",
    "\n",
    "        print(\"   >>> Facility Id\",latest_site_id)\n",
    "        print(\"   >>> Facility Name\",facility_name)\n",
    "  \n",
    "\n",
    "        # ART ----------------\n",
    "        art_df = extraction.extracting_data(\"\"\"\n",
    "                                        select \n",
    "                                            p.person_id,\n",
    "                                            p.firstname,\n",
    "                                            p.lastname,\n",
    "                                            p.birthdate,\n",
    "                                            p.sex,\n",
    "                                            pp.client_profile,\n",
    "                                            a.art_id, \n",
    "                                            pt.patient_id,\n",
    "                                            a.art_number ,\n",
    "                                            a.date_of_hiv_test as 'Date of HIV diagnosis',\n",
    "                                            a.date_enrolled as 'Date of enrolment in care',\n",
    "                                            pt.time as 'Date of ART visit',\n",
    "                                            v.lactating_status as 'Pregnancy Status',\n",
    "                                            w.value as 'Weight',\n",
    "                                            pt.back_captured,\n",
    "                                            pt.back_captured_by\n",
    "                                        from consultation.art a\n",
    "                                            left join  client.person p\n",
    "                                            on a.person_id = p.person_id\n",
    "                                            \n",
    "                                            left join consultation.patient_client_profile pp\n",
    "                                            on p.person_id = pp.person_id\n",
    "                                            \n",
    "                                            left join consultation.art_visit v\n",
    "                                            on a.art_id = v.art_id\n",
    "                                            \n",
    "                                            left join consultation.patient pt\n",
    "                                            on v.patient_id = pt.patient_id\n",
    "                                            \n",
    "                                            left join consultation.weight w\n",
    "                                            on v.patient_id = w.patient_id\n",
    "    \n",
    "                                                            \"\"\", connection)\n",
    "        art_df['Date of ART visit'] = pd.to_datetime(art_df['Date of ART visit'],errors='coerce',format='mixed')\n",
    "        art_df['Date of ART visit'] = art_df['Date of ART visit'].dt.date\n",
    "        \n",
    "\n",
    "        art_start_date = extraction.extracting_data(\"\"\"\n",
    "                                                    select \n",
    "                                                        art_id, date as 'Art Initiation Date', state,\n",
    "                                                        art_initiation_category\n",
    "                                                    from consultation.art_current_status\n",
    "                                                        order by art_id, date\n",
    "                                                    \"\"\",connection\n",
    "                                                    )\n",
    "        art_start_date_unique = art_start_date.drop_duplicates(subset=['art_id'],keep='first').drop('art_initiation_category', axis=1)\n",
    "\n",
    "        patient_tb_screening = extraction.extracting_data(\"\"\"\n",
    "                                                        select \n",
    "                                                           p.patient_id,\n",
    "                                                           p.time as 'Date of TB screening 4WSS',\n",
    "                                                           tb.presumptive as 'Screening results (4WSS)'\n",
    "                                                        from consultation.patient_tb_screening tb\n",
    "                                                           left join consultation.patient p\n",
    "                                                           on tb.patient_id = p.patient_id\n",
    "                                                          \"\"\", connection)\n",
    "        patient_tb_screening['Screening results (4WSS)'] = patient_tb_screening['Screening results (4WSS)'].replace(\n",
    "             {0:'Not Presumptive',1:'Presumptive'})\n",
    "    \n",
    "        art_who_stage = extraction.extracting_data(\"\"\"\n",
    "                                                    select \n",
    "                                                        art_id ,\n",
    "                                                        date as 'Date of ART visit',\n",
    "                                                        stage as 'WHO stage at TB screening'\n",
    "                                                    from \n",
    "                                                        consultation.art_who_stage \n",
    "                                                   \"\"\", connection)\n",
    "        \n",
    "        art_tpt = extraction.extracting_data(\"\"\"\n",
    "                                            select \n",
    "                                             art_id,\n",
    "                                             date as 'Date of ART visit',\n",
    "                                             status as 'TPT status at TB screening'\n",
    "                                             from consultation.art_ipt\n",
    "                                             \"\"\",connection)\n",
    "        \n",
    "\n",
    "        tb_lam = extraction.extracting_data(\"\"\"\n",
    "                                            select\n",
    "                                            person_id, \n",
    "                                            date,\n",
    "                                            test,\n",
    "                                            result,\n",
    "                                            from consultation.person_investigation \n",
    "                                            where test = \"tb lam\"\n",
    "                                            \"\"\",connection)\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        merge = pd.merge(art_df,art_start_date_unique, on =['art_id'],how = 'left')\n",
    "        \n",
    "        merge1 = pd.merge(merge,patient_tb_screening, on =['patient_id'],how = 'left')\n",
    "\n",
    "        merge2 = pd.merge(merge1, art_who_stage, on = ['art_id','Date of ART visit'], how = 'left')\n",
    "\n",
    "        # merge tpt\n",
    "        merge3 = pd.merge(merge2,art_tpt , on = ['art_id','Date of ART visit'], how = 'left')\n",
    "        \n",
    "        merge = pd.merge()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /home/tynash/anaconda/lib/python3.9/site-packages (1.22.4)\n",
      "\u001b[31mERROR: Could not find a version that satisfies the requirement 1.20 (from versions: none)\u001b[0m\n",
      "\u001b[31mERROR: No matching distribution found for 1.20\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
