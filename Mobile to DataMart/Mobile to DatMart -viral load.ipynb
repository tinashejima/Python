{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data fetch cycle.\n",
      ">>> Initial snapshot\n",
      "Fetching batch data where event_date > 1900-01-01 00:00:00\n",
      "Fetched batch data: (18306, 26)\n",
      "Inserting new record for encounter_id: 0847e050-1167-48d1-b1a1-82eb0be67ca9\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'date_of_viral_load_results'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\AnesuLeenMutonga\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date_of_viral_load_results'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 296\u001b[0m\n\u001b[0;32m    292\u001b[0m     pg_conn\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    295\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 296\u001b[0m     main()\n",
      "Cell \u001b[1;32mIn[10], line 289\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    287\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mob_conn\u001b[38;5;241m.\u001b[39mconnect() \u001b[38;5;129;01mand\u001b[39;00m pg_conn\u001b[38;5;241m.\u001b[39mconnect():\n\u001b[0;32m    288\u001b[0m     data_fetcher \u001b[38;5;241m=\u001b[39m DataFetcher(mob_conn, pg_conn)\n\u001b[1;32m--> 289\u001b[0m     data_fetcher\u001b[38;5;241m.\u001b[39mstart_polling()\n\u001b[0;32m    291\u001b[0m mob_conn\u001b[38;5;241m.\u001b[39mclose()\n\u001b[0;32m    292\u001b[0m pg_conn\u001b[38;5;241m.\u001b[39mclose()\n",
      "Cell \u001b[1;32mIn[10], line 264\u001b[0m, in \u001b[0;36mDataFetcher.start_polling\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    262\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m    263\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStarting data fetch cycle.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfetch_data_in_batches()\n\u001b[0;32m    265\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWaiting for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolling_interval\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds before next fetch.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    266\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolling_interval)\n",
      "Cell \u001b[1;32mIn[10], line 160\u001b[0m, in \u001b[0;36mDataFetcher.fetch_data_in_batches\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    152\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFetched batch data:\u001b[39m\u001b[38;5;124m\"\u001b[39m, df\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m    154\u001b[0m \u001b[38;5;66;03m# Add hash column to the DataFrame\u001b[39;00m\n\u001b[0;32m    155\u001b[0m \u001b[38;5;66;03m# df['record_hash'] = df.apply(lambda row: self.hash_record(row), axis=1)\u001b[39;00m\n\u001b[0;32m    156\u001b[0m \n\u001b[0;32m    157\u001b[0m \u001b[38;5;66;03m#df.to_csv(\"outputwithdps.csv\", index=False)\u001b[39;00m\n\u001b[0;32m    158\u001b[0m \u001b[38;5;66;03m#pprint()\u001b[39;00m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;66;03m# Process and update the last_processed_value\u001b[39;00m\n\u001b[1;32m--> 160\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocess_data(df)\n\u001b[0;32m    162\u001b[0m \u001b[38;5;66;03m# Update the last_processed_value to the latest timestamp in the batch\u001b[39;00m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlast_processed_value \u001b[38;5;241m=\u001b[39m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_date\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\n",
      "Cell \u001b[1;32mIn[10], line 249\u001b[0m, in \u001b[0;36mDataFetcher.process_data\u001b[1;34m(self, df)\u001b[0m\n\u001b[0;32m    220\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInserting new record for encounter_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mencounter_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    221\u001b[0m insert_query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    222\u001b[0m \u001b[38;5;124mINSERT INTO marts.dm_viral_load_test (\u001b[39m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;124m    art_number, lab_request_number, age, sex, facility_id_code,\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    240\u001b[0m \u001b[38;5;124m) VALUES (\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m, NOW(), \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m)\u001b[39m\n\u001b[0;32m    241\u001b[0m \u001b[38;5;124m\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m    242\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpg_conn\u001b[38;5;241m.\u001b[39mexecute_query(insert_query, (\n\u001b[0;32m    243\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mart_number\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlaboratory_request_number\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mage\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m    244\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msex\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfacility_id\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclient_profile\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    245\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcurrent_art_regimen\u001b[39m\u001b[38;5;124m'\u001b[39m], row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_of_art_initiation\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m    246\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mreason_for_viral_load_test\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    247\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_of_viral_sample_collection\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m    248\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype_of_viral_load_sample\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[1;32m--> 249\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_of_viral_load_results\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    250\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mviral_load_results\u001b[39m\u001b[38;5;124m'\u001b[39m],row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_viral_load_results_issued_to_client\u001b[39m\u001b[38;5;124m'\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    251\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_of_hiv_drug_resistance_sample_collection\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    252\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtype_of_hiv_drug_resistance_sample_collected\u001b[39m\u001b[38;5;124m'\u001b[39m], \n\u001b[0;32m    253\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdate_hiv_drug_resistance_result_received\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    254\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhiv_drug_resistance_results\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    255\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mswitched_to_third_line_regimen\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    256\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthird_line_regimen\u001b[39m\u001b[38;5;124m'\u001b[39m],\n\u001b[0;32m    257\u001b[0m     row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mevent_date\u001b[39m\u001b[38;5;124m'\u001b[39m], encounter_id\n\u001b[0;32m    258\u001b[0m ))\n",
      "File \u001b[1;32mc:\\Users\\AnesuLeenMutonga\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_value(key)\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\AnesuLeenMutonga\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mget_loc(label)\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\AnesuLeenMutonga\\anaconda3\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'date_of_viral_load_results'"
     ]
    }
   ],
   "source": [
    "from pyhive import hive\n",
    "import psycopg2\n",
    "import pandas as pd\n",
    "import hashlib\n",
    "import time\n",
    "import math\n",
    "\n",
    "class MobileConnection:\n",
    "    def __init__(self, dbname, user, password, host, port):\n",
    "        self.dbname = dbname\n",
    "        self.user = user\n",
    "        self.password = password\n",
    "        self.host = host\n",
    "        self.port = port\n",
    "        self.connection = None\n",
    "        self.cursor = None\n",
    "\n",
    "    def connect(self):\n",
    "        \"\"\"Creates a connection to the Postgres Mobile database.\"\"\"\n",
    "        try:\n",
    "            self.connection = psycopg2.connect(\n",
    "                dbname=self.dbname,\n",
    "                user=self.user,\n",
    "                password=self.password,\n",
    "                host=self.host,\n",
    "                port=self.port\n",
    "            )\n",
    "            self.connection.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "            self.cursor = self.connection.cursor()\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating PostgreSQL Mobile connection: {e}\")\n",
    "            return False\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Closes the connection to the Mobile database.\"\"\"\n",
    "        if self.connection:\n",
    "            try:\n",
    "                self.connection.close()\n",
    "            except Exception as e:\n",
    "                print(f\"Error closing connection: {e}\")\n",
    "\n",
    "    def execute_query(self, query):\n",
    "        \"\"\"Executes the given query and returns the results.\"\"\"\n",
    "        try:\n",
    "            cursor = self.connection.cursor()\n",
    "            cursor.execute(query)\n",
    "            columns = [desc[0] for desc in cursor.description]\n",
    "            results = cursor.fetchall()\n",
    "            return results, columns\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing query: {e}\")\n",
    "            return None\n",
    "        finally:\n",
    "            cursor.close()\n",
    "\n",
    "\n",
    "class PostgresConnection:\n",
    "    def __init__(self, dbname, user, password, host, port):\n",
    "        self.dbname = dbname\n",
    "        self.user = user\n",
    "        self.password = password\n",
    "        self.host = host\n",
    "        self.port = port\n",
    "        self.connection = None\n",
    "        self.cursor = None\n",
    "\n",
    "    def connect(self):\n",
    "        \"\"\"Creates a connection to the PostgreSQL database.\"\"\"\n",
    "        try:\n",
    "            self.connection = psycopg2.connect(\n",
    "                dbname=self.dbname,\n",
    "                user=self.user,\n",
    "                password=self.password,\n",
    "                host=self.host,\n",
    "                port=self.port\n",
    "            )\n",
    "            self.connection.set_isolation_level(psycopg2.extensions.ISOLATION_LEVEL_AUTOCOMMIT)\n",
    "            self.cursor = self.connection.cursor()\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error creating PostgreSQL connection: {e}\")\n",
    "            return False\n",
    "\n",
    "    def execute_query(self, query, params=None):\n",
    "        \"\"\"Executes a query with optional parameters for SELECT, INSERT, or UPDATE operations.\"\"\"\n",
    "        try:\n",
    "            # Execute the query with parameters\n",
    "            self.cursor.execute(query, params)\n",
    "\n",
    "            # Check if the query is a SELECT statement\n",
    "            if query.strip().upper().startswith(\"SELECT\"):\n",
    "                # Fetch and return results for SELECT queries\n",
    "                return self.cursor.fetchall()\n",
    "            else:\n",
    "                # Commit transaction for non-SELECT queries (e.g., INSERT, UPDATE)\n",
    "                self.connection.commit()\n",
    "                return True  # Return True to indicate success for INSERT/UPDATE queries\n",
    "        except Exception as e:\n",
    "            print(f\"Error executing PostgreSQL query: {e}\")\n",
    "            return None\n",
    "\n",
    "    def close(self):\n",
    "        \"\"\"Closes the PostgreSQL database connection.\"\"\"\n",
    "        if self.connection:\n",
    "            try:\n",
    "                self.connection.close()\n",
    "            except Exception as e:\n",
    "                print(f\"Error closing PostgreSQL connection: {e}\")\n",
    "\n",
    "\n",
    "class DataFetcher:\n",
    "    def __init__(self, mob_conn, pg_conn, batch_size=50000, polling_interval=600):\n",
    "        self.mob_conn = mob_conn\n",
    "        self.pg_conn = pg_conn\n",
    "        self.batch_size = batch_size\n",
    "        self.polling_interval = polling_interval\n",
    "        self.last_processed_value = '1900-01-01 00:00:00'\n",
    "\n",
    "    def check_if_snapshot_done(self):\n",
    "        query = \"SELECT event_date FROM marts.dm_viral_load_test ORDER BY event_date DESC LIMIT 1\"\n",
    "        result = self.pg_conn.execute_query(query)\n",
    "        if result:\n",
    "            return result[0][0]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def fetch_data_in_batches(self):\n",
    "        snapshot_date = self.check_if_snapshot_done()\n",
    "        if snapshot_date:\n",
    "            self.last_processed_value = snapshot_date\n",
    "            print(\">>> Detected Snapshot done:\", self.last_processed_value)\n",
    "        else:\n",
    "            print(\">>> Initial snapshot\")\n",
    "\n",
    "        while True:\n",
    "            print(f\"Fetching batch data where event_date > {self.last_processed_value}\")\n",
    "            query = f\"\"\"\n",
    "            SELECT * FROM report.viral_load\n",
    "            WHERE event_date > '{self.last_processed_value}' \n",
    "            ORDER BY event_date ASC LIMIT {self.batch_size}\n",
    "            \"\"\"\n",
    "\n",
    "            \n",
    "            batch_data, columns = self.mob_conn.execute_query(query)\n",
    "\n",
    "            if not batch_data:  # No more data\n",
    "                print(\"No more data to fetch. Ending batch fetching.\")\n",
    "                break\n",
    "            \n",
    "            df = pd.DataFrame(batch_data, columns=columns)\n",
    "            print(\"Fetched batch data:\", df.shape)\n",
    "\n",
    "            # Add hash column to the DataFrame\n",
    "            # df['record_hash'] = df.apply(lambda row: self.hash_record(row), axis=1)\n",
    "\n",
    "            #df.to_csv(\"outputwithdps.csv\", index=False)\n",
    "            #pprint()\n",
    "            # Process and update the last_processed_value\n",
    "            self.process_data(df)\n",
    "\n",
    "            # Update the last_processed_value to the latest timestamp in the batch\n",
    "\n",
    "            self.last_processed_value = df['event_date'].max()\n",
    "            print(\"Updated last_processed_value to:\", self.last_processed_value)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def process_data(self, df):\n",
    "        \"\"\"Processes the data batch by cleaning and then inserting/updating it in PostgreSQL.\"\"\"\n",
    "      \n",
    "        for _, row in df.iterrows():\n",
    "            encounter_id = row['encounter_id']\n",
    "            check_query = \"SELECT 1 FROM marts.dm_viral_load_test WHERE encounter_id = %s\"\n",
    "            if self.pg_conn.execute_query(check_query, (encounter_id,)):\n",
    "                # Update existing record\n",
    "                print(f\"Updating record for encounter_id: {encounter_id}\")\n",
    "                update_query = \"\"\"\n",
    "                UPDATE marts.dm_viral_load_test\n",
    "                SET art_number = %s, lab_request_number = %s, age = %s, sex = %s,\n",
    "                    facility_id_code = %s,\n",
    "                    client_profile = %s, current_art_regimen = %s,\n",
    "                    date_of_art_initiation = %s,\n",
    "                    reason_for_viral_load_testing = %s,\n",
    "                    date_of_viral_load_sample_collection = %s,\n",
    "                    type_of_viral_load_sample = %s,\n",
    "                    date_of_viral_load_results = %s,\n",
    "                    viral_load_results = %s, \n",
    "                    date_viral_load_results_issued_to_client =%s,\n",
    "                    reason_for_hiv_drug_resistance_testing =%s,\n",
    "                    date_of_hiv_drug_resistance_sample_collection =%s,\n",
    "                    type_of_hiv_drug_resistance_sample_collected = %s,\n",
    "                    date_hiv_drug_resistance_result_received = %s,\n",
    "                    hiv_drug_resistance_results =%s,\n",
    "                    switched_to_3rd_line =%s,\n",
    "                    \"3rd_line_regimen\" =%s,\n",
    "                    event_date= %s, dm_date_created = NOW()\n",
    "                WHERE encounter_id = %s\n",
    "                \"\"\"\n",
    "                self.pg_conn.execute_query(update_query, (\n",
    "                    row['art_number'], row['laboratory_request_number'], row['age'], \n",
    "                    row['sex'], row['facility_id'], row['client_profile'],\n",
    "                    row['current_art_regimen'], row['date_of_art_initiation'], \n",
    "                    row['reason_for_viral_load_test'],\n",
    "                    row['date_of_viral_load_sample_collection'], \n",
    "                    row['type_of_viral_load_sample'],\n",
    "                    row['date_of_viral_load_results'],\n",
    "                    row['viral_load_results'],row['date_viral_load_results_issued_to_client'], '',\n",
    "                    row['date_of_hiv_drug_resistance_sample_collection'],\n",
    "                    row['type_of_hiv_drug_resistance_sample_collected'], \n",
    "                    row['date_hiv_drug_resistance_result_received'],\n",
    "                    row['hiv_drug_resistance_results'],\n",
    "                    row['switched_to_third_line_regimen'],\n",
    "                    row['third_line_regimen'],\n",
    "                    row['event_date'], encounter_id\n",
    "                ))\n",
    "            else:\n",
    "                # Insert new record\n",
    "                print(f\"Inserting new record for encounter_id: {encounter_id}\")\n",
    "                insert_query = \"\"\"\n",
    "                INSERT INTO marts.dm_viral_load_test (\n",
    "                    art_number, lab_request_number, age, sex, facility_id_code,\n",
    "                    client_profile, current_art_regimen  ,\n",
    "                    date_of_art_initiation  ,\n",
    "                    reason_for_viral_load_testing  ,\n",
    "                    date_of_viral_load_sample_collection  ,\n",
    "                    type_of_viral_load_sample  ,\n",
    "                      date_of_viral_load_results  ,\n",
    "                    viral_load_results  , \n",
    "                    date_viral_load_results_issued_to_client ,\n",
    "                    reason_for_hiv_drug_resistance_testing ,\n",
    "                    date_of_hiv_drug_resistance_sample_collection ,\n",
    "                    type_of_hiv_drug_resistance_sample_collected  ,\n",
    "                    date_hiv_drug_resistance_result_received  ,\n",
    "                    hiv_drug_resistance_results ,\n",
    "                    switched_to_3rd_line ,\n",
    "                    \"3rd_line_regimen\",\n",
    "                    event_date, dm_date_created, encounter_id\n",
    "                ) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, NOW(), %s)\n",
    "                \"\"\"\n",
    "                self.pg_conn.execute_query(insert_query, (\n",
    "                    row['art_number'], row['laboratory_request_number'], row['age'], \n",
    "                    row['sex'], row['facility_id'], row['client_profile'],\n",
    "                    row['current_art_regimen'], row['date_of_art_initiation'], \n",
    "                    row['reason_for_viral_load_test'],\n",
    "                    row['date_of_viral_sample_collection'], \n",
    "                    row['type_of_viral_load_sample'],\n",
    "                    row['date_of_viral_load_results'],\n",
    "                    row['viral_load_results'],row['date_viral_load_results_issued_to_client'], '',\n",
    "                    row['date_of_hiv_drug_resistance_sample_collection'],\n",
    "                    row['type_of_hiv_drug_resistance_sample_collected'], \n",
    "                    row['date_hiv_drug_resistance_result_received'],\n",
    "                    row['hiv_drug_resistance_results'],\n",
    "                    row['switched_to_third_line_regimen'],\n",
    "                    row['third_line_regimen'],\n",
    "                    row['event_date'], encounter_id\n",
    "                ))\n",
    "\n",
    "    def start_polling(self):\n",
    "        \"\"\"Starts polling to fetch data every 5 minutes.\"\"\"\n",
    "        while True:\n",
    "            print(\"Starting data fetch cycle.\")\n",
    "            self.fetch_data_in_batches()\n",
    "            print(f\"Waiting for {self.polling_interval} seconds before next fetch.\")\n",
    "            time.sleep(self.polling_interval)\n",
    "\n",
    "def main():\n",
    "    # Initialize Mobile connection\n",
    "    mob_conn = MobileConnection(\n",
    "        dbname=\"master\",\n",
    "        user=\"postgres\",\n",
    "        password=\"wGMCAE6zFHcyrBmXtus97JPanxvkY4fb\",\n",
    "        host=\"127.0.0.1\",\n",
    "        port=5434\n",
    "    )\n",
    "\n",
    "    # Initialize PostgreSQL connection\n",
    "    pg_conn = PostgresConnection(\n",
    "        dbname=\"HTSDATA\",\n",
    "        user=\"postgres\",\n",
    "        password=\"wGMCAE6zFHcyrBmXtus97JPanxvkY4fb\",\n",
    "        host=\"127.0.0.1\",\n",
    "        port=5431\n",
    "    )\n",
    "\n",
    "    if mob_conn.connect() and pg_conn.connect():\n",
    "        data_fetcher = DataFetcher(mob_conn, pg_conn)\n",
    "        data_fetcher.start_polling()\n",
    "\n",
    "    mob_conn.close()\n",
    "    pg_conn.close()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
